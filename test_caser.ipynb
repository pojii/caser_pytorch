{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelArgs:\n",
    "    def __init__(self, d, nv, nh, drop, ac_conv, ac_fc, L):\n",
    "        self.d = d\n",
    "        self.nv = nv\n",
    "        self.nh = nh\n",
    "        self.drop = drop\n",
    "        self.ac_conv = ac_conv\n",
    "        self.ac_fc = ac_fc\n",
    "        self.L = L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sequences after filtering: 635\n",
      "[109]\n",
      "[-6.6100044]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\COMPUTER15\\AppData\\Local\\Temp\\ipykernel_5976\\2622337046.py:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('thairobotics_finetuned_model.pth', map_location=torch.device('cpu')))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from caser import Caser  # Assuming you have a Caser class defined\n",
    "from interactions import Interactions  # Assuming you have an Interactions class defined\n",
    "import numpy as np\n",
    "\n",
    "# Define the model architecture with the correct number of users and items\n",
    "num_users = 5848  # Replace with the actual number of users used during training\n",
    "num_items = 235  # Replace with the actual number of items used during training\n",
    "model_args = ModelArgs(\n",
    "    d=512,\n",
    "    nv=4,\n",
    "    nh=16,\n",
    "    drop=0.5,\n",
    "    ac_conv='relu',\n",
    "    ac_fc='relu',\n",
    "    L=5  # Set the value for L\n",
    ")\n",
    "\n",
    "model = Caser(num_users, num_items, model_args)\n",
    "\n",
    "# Load the state dictionary\n",
    "model.load_state_dict(torch.load('thairobotics_finetuned_model.pth', map_location=torch.device('cpu')))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Load the test data\n",
    "test_data = Interactions('datasets/coursera_thairobotics/test.txt')\n",
    "\n",
    "# Transform interactions to sequences\n",
    "test_data.to_sequence(sequence_length=5, target_length=1)\n",
    "\n",
    "def predict_for_user(model, user_id, item_ids):\n",
    "    with torch.no_grad():\n",
    "        sequences_np = test_data.test_sequences.sequences[user_id, :]\n",
    "        sequences_np = np.atleast_2d(sequences_np)\n",
    "\n",
    "        sequences = torch.from_numpy(sequences_np).long()\n",
    "        item_ids = torch.from_numpy(item_ids).long()\n",
    "        user_id = torch.from_numpy(np.array([[user_id]])).long()\n",
    "\n",
    "        # Reshape inputs\n",
    "        sequences = sequences.unsqueeze(0)\n",
    "        user_id = user_id.squeeze(1)\n",
    "\n",
    "        out = model(sequences, user_id, item_ids, for_pred=True)\n",
    "    return out.cpu().numpy().flatten()\n",
    "\n",
    "# Example usage\n",
    "user_id = 0  # Replace with the actual user ID\n",
    "item_ids = np.array([109])  # Replace with the actual item IDs\n",
    "print(item_ids)\n",
    "predictions = predict_for_user(model, user_id, item_ids)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Courses: [ 0 22  2  1 17]\n",
      "Scores: [2.8250961 1.7911837 1.5722692 1.2321384 1.0935287]\n"
     ]
    }
   ],
   "source": [
    "def get_recommendations(model, user_id, num_recommendations=5):\n",
    "    # ทำนายคะแนนสำหรับคอร์สเรียนทั้งหมด\n",
    "    item_ids = np.arange(test_data.num_items)\n",
    "    predictions = predict_for_user(model, user_id, item_ids)\n",
    "    \n",
    "    # เลือกคอร์สเรียนที่มีคะแนนสูงสุด\n",
    "    top_indices = np.argsort(predictions)[-num_recommendations:][::-1]\n",
    "    top_scores = predictions[top_indices]\n",
    "    \n",
    "    return top_indices, top_scores\n",
    "\n",
    "# ตัวอย่างการใช้งาน\n",
    "user_id = 0  # แทนที่ด้วย user ID ที่ต้องการ\n",
    "num_recommendations = 5  # จำนวนคอร์สเรียนที่ต้องการแนะนำ\n",
    "recommended_courses, scores = get_recommendations(model, user_id, num_recommendations)\n",
    "print(\"Recommended Courses:\", recommended_courses)\n",
    "print(\"Scores:\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Courses: [ 0 22  2 25  5]\n",
      "Scores: [2.5309947 2.0901287 1.4136686 1.3145612 1.091479 ]\n",
      "Course ID: 0, Course Name: Support Vector Machine\n",
      "Course ID: 22, Course Name: Fundamental Mathematics for Robotics (Ordinary Differential Equations)\n",
      "Course ID: 2, Course Name: PRE – TEST RAC 2566\n",
      "Course ID: 25, Course Name: Introduction to Deep Learning for Sequential Data\n",
      "Course ID: 5, Course Name: Introduction to Augmented Reality\n",
      "User 202 has taken the following courses:\n",
      "Course ID: 25, Course Name: Introduction to Deep Learning for Sequential Data\n"
     ]
    }
   ],
   "source": [
    "# ฟังก์ชั่นเพื่ออ่านไฟล์ text.txt และสร้างแผนที่ระหว่าง ID ของคอร์สและชื่อคอร์ส\n",
    "def load_course_names(file_path):\n",
    "    course_names = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:  # ระบุการเข้ารหัสเป็น utf-8\n",
    "        for line in file:\n",
    "            parts = line.strip().split(' ', 1)  # แยกด้วยช่องว่างครั้งแรกเท่านั้น\n",
    "            if len(parts) == 2:\n",
    "                course_id, course_name = parts\n",
    "                course_names[int(course_id)] = course_name\n",
    "    return course_names\n",
    "\n",
    "# โหลดชื่อคอร์สจากไฟล์ text.txt\n",
    "course_names = load_course_names(r'datasets\\coursera_thairobotics\\text.txt')\n",
    "\n",
    "# ฟังก์ชั่นเพื่อแสดงชื่อคอร์สที่แนะนำ\n",
    "def display_recommended_courses(recommended_courses, course_names):\n",
    "    for course_id in recommended_courses:\n",
    "        print(f\"Course ID: {course_id}, Course Name: {course_names.get(course_id, 'Unknown')}\")\n",
    "\n",
    "# ตัวอย่างการใช้งาน\n",
    "user_id = 202  # แทนที่ด้วย user ID ที่ต้องการ\n",
    "num_recommendations = 5  # จำนวนคอร์สเรียนที่ต้องการแนะนำ\n",
    "recommended_courses, scores = get_recommendations(model, user_id, num_recommendations)\n",
    "print(\"Recommended Courses:\", recommended_courses)\n",
    "print(\"Scores:\", scores)\n",
    "\n",
    "# แสดงชื่อคอร์สที่แนะนำ\n",
    "display_recommended_courses(recommended_courses, course_names)\n",
    "\n",
    "# ฟังก์ชั่นเพื่อดึงข้อมูลการเรียนของผู้ใช้\n",
    "def get_user_courses(interactions, user_id):\n",
    "    user_indices = np.where(interactions.user_ids == user_id)[0]\n",
    "    user_courses = interactions.item_ids[user_indices]\n",
    "    return user_courses\n",
    "\n",
    "# โหลดข้อมูลการเรียนจากไฟล์ interactions\n",
    "interactions = Interactions('datasets/coursera_thairobotics/test.txt')\n",
    "\n",
    "user_courses = get_user_courses(interactions, user_id)\n",
    "\n",
    "# แสดงชื่อคอร์สที่ผู้ใช้ได้เรียน\n",
    "print(f\"User {user_id} has taken the following courses:\")\n",
    "for course_id in user_courses:\n",
    "    print(f\"Course ID: {course_id}, Course Name: {course_names.get(course_id, 'Unknown')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Courses taken by user 0 in the train dataset:\n",
      "Course ID: 8.0, Course Name: Robotic Automation Systems (PLC)\n",
      "Course ID: 43.0, Course Name: Machine Learning for Robotics\n",
      "Course ID: 11.0, Course Name: Internet of Things Applications\n",
      "Course ID: 1.0, Course Name: Dimensionality Reduction\n",
      "Course ID: 25.0, Course Name: Introduction to Deep Learning for Sequential Data\n",
      "Course ID: 27.0, Course Name: Introduction to Robotics\n",
      "Course ID: 24.0, Course Name: Object Localization Using Gradient-Weighted Class Activation Mapping (Grad-CAM)\n",
      "Course ID: 26.0, Course Name: Introduction to Neural Networks and How it Learns ?\n",
      "\n",
      "Total number of courses taken by user 0: 8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# อ่านไฟล์ train.txt\n",
    "train_data = pd.read_csv('datasets/coursera_thairobotics/train.txt', sep=' ', header=None, names=['user_id', 'course_id', 'interaction'])\n",
    "\n",
    "# กรองข้อมูลเฉพาะ user_id = 0\n",
    "user_0_courses = train_data[train_data['user_id'] == 0]\n",
    "\n",
    "# แสดงคอร์สที่ user 0 เรียน\n",
    "print(\"Courses taken by user 0 in the train dataset:\")\n",
    "for _, row in user_0_courses.iterrows():\n",
    "    course_id = row['course_id']\n",
    "    course_name = course_names.get(course_id, \"Unknown Course\")\n",
    "    print(f\"Course ID: {course_id}, Course Name: {course_name}\")\n",
    "\n",
    "# แสดงจำนวนคอร์สที่ user 0 เรียน\n",
    "print(f\"\\nTotal number of courses taken by user 0: {len(user_0_courses)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All item IDs:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274]\n",
      "\n",
      "Randomly selected 10 courses:\n",
      "Course ID: 141, Course Name: Dynamic Programming, Greedy Algorithms\n",
      "Course ID: 271, Course Name: Sales and CRM Overview\n",
      "Course ID: 6, Course Name: 3D Design with Onshape\n",
      "Course ID: 140, Course Name: Innovative Finance: Hacking finance to change the world\n",
      "Course ID: 109, Course Name: Introduction to MongoDB\n",
      "Course ID: 220, Course Name: Google Docs\n",
      "Course ID: 249, Course Name: Improving Deep Neural Networks: Hyperparameter Tuning, Regularization and Optimization\n",
      "Course ID: 142, Course Name: Mathematics for Machine Learning: Linear Algebra\n",
      "Course ID: 258, Course Name: Python Basics\n",
      "Course ID: 139, Course Name: Data Analysis with Spreadsheets and SQL\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# แสดง item id ทั้งหมด\n",
    "print(\"All item IDs:\")\n",
    "print(list(course_names.keys()))\n",
    "\n",
    "# สุ่มเลือก 10 ชื่อคอร์ส\n",
    "random_courses = random.sample(list(course_names.items()), 10)\n",
    "\n",
    "print(\"\\nRandomly selected 10 courses:\")\n",
    "for course_id, course_name in random_courses:\n",
    "    print(f\"Course ID: {course_id}, Course Name: {course_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caser_venv_py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
