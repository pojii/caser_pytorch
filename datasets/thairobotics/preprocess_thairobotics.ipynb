{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anonymized data saved to 'anonymized_combined_output.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# อ่านไฟล์ combined_output.csv\n",
    "df = pd.read_csv('combined_output.csv')\n",
    "\n",
    "# ฟังก์ชันเพื่อสร้าง anonymous name และ email\n",
    "def anonymize_data(df):\n",
    "    unique_pairs = {}\n",
    "    counter = 1\n",
    "\n",
    "    # Loop ผ่านข้อมูลทุกแถว\n",
    "    for index, row in df.iterrows():\n",
    "        name_email_pair = (row['Name'], row['Email'])\n",
    "        \n",
    "        if name_email_pair not in unique_pairs:\n",
    "            # สร้างค่า anonymous ใหม่สำหรับชื่อและอีเมล์\n",
    "            unique_pairs[name_email_pair] = (f'User{counter}', f'user{counter}@anon.com')\n",
    "            counter += 1\n",
    "        \n",
    "        # แทนที่ชื่อและอีเมล์ด้วย anonymous ที่สร้าง\n",
    "        df.at[index, 'Name'], df.at[index, 'Email'] = unique_pairs[name_email_pair]\n",
    "    \n",
    "    return df\n",
    "\n",
    "# เรียกใช้ฟังก์ชันเพื่อทำการ anonymize\n",
    "df_anonymized = anonymize_data(df)\n",
    "\n",
    "# บันทึกไฟล์ที่ทำการ anonymize แล้ว\n",
    "df_anonymized.to_csv('anonymized_combined_output.csv', index=False)\n",
    "\n",
    "print(\"Anonymized data saved to 'anonymized_combined_output.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files saved as train.txt, val.txt, test.txt, and text.txt.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the anonymized CSV file\n",
    "df = pd.read_csv('anonymized_combined_output.csv')\n",
    "\n",
    "# Step 1: Create a mapping from course name to a unique ID (for text.txt)\n",
    "course_name_map = {name: idx for idx, name in enumerate(df['Course Name'].unique())}\n",
    "\n",
    "# Step 2: Apply the mapping to the DataFrame\n",
    "df['course_id_mapped'] = df['Course Name'].map(course_name_map)\n",
    "\n",
    "# Step 3: Create user mappings to unique IDs (for consistency in train/test/val split)\n",
    "user_name_map = {name: idx for idx, name in enumerate(df['Name'].unique())}\n",
    "df['user_id_mapped'] = df['Name'].map(user_name_map)\n",
    "\n",
    "# Step 4: Keep only the relevant columns\n",
    "df = df[['user_id_mapped', 'course_id_mapped', 'Progress']]\n",
    "\n",
    "# Convert 'Progress' to binary (1 for progress > 0, 0 otherwise)\n",
    "df['Progress'] = df['Progress'].apply(lambda x: 1 if int(x.strip('%')) > 0 else 0)\n",
    "\n",
    "# Step 5: Split the data into train, val, and test sets\n",
    "train, temp = train_test_split(df, test_size=0.3, random_state=42)\n",
    "val, test = train_test_split(temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Step 6: Save the train, val, and test sets as .txt files\n",
    "train.to_csv('train.txt', sep=' ', header=False, index=False)\n",
    "val.to_csv('val.txt', sep=' ', header=False, index=False)\n",
    "test.to_csv('test.txt', sep=' ', header=False, index=False)\n",
    "\n",
    "# Step 7: Save the course name mapping as text.txt\n",
    "# Step 7: Save the course name mapping as text.txt\n",
    "with open('text.txt', 'w', encoding='utf-8') as f:\n",
    "    for course_name, course_id in course_name_map.items():\n",
    "        f.write(f\"{course_id} {course_name}\\n\")\n",
    "\n",
    "\n",
    "print(\"Files saved as train.txt, val.txt, test.txt, and text.txt.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-text in c:\\users\\computer15\\desktop\\caser_pytorch\\caser_venv_py39\\lib\\site-packages (2.10.0)\n",
      "Requirement already satisfied: tensorflow-hub>=0.8.0 in c:\\users\\computer15\\desktop\\caser_pytorch\\caser_venv_py39\\lib\\site-packages (from tensorflow-text) (0.16.1)\n",
      "Requirement already satisfied: tensorflow<2.11,>=2.10.0 in c:\\users\\computer15\\desktop\\caser_pytorch\\caser_venv_py39\\lib\\site-packages (from tensorflow-text) (2.10.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\computer15\\desktop\\caser_pytorch\\caser_venv_py39\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\computer15\\desktop\\caser_pytorch\\caser_venv_py39\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\computer15\\desktop\\caser_pytorch\\caser_venv_py39\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (24.3.25)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\computer15\\desktop\\caser_pytorch\\caser_venv_py39\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\computer15\\desktop\\caser_pytorch\\caser_venv_py39\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\computer15\\desktop\\caser_pytorch\\caser_venv_py39\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (3.11.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\computer15\\desktop\\caser_pytorch\\caser_venv_py39\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (1.1.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\computer15\\desktop\\caser_pytorch\\caser_venv_py39\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (18.1.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\computer15\\desktop\\caser_pytorch\\caser_venv_py39\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (1.26.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\computer15\\desktop\\caser_pytorch\\caser_venv_py39\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\computer15\\desktop\\caser_pytorch\\caser_venv_py39\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (24.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\computer15\\desktop\\caser_pytorch\\caser_venv_py39\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (3.19.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\computer15\\desktop\\caser_pytorch\\caser_venv_py39\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (58.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\computer15\\desktop\\caser_pytorch\\caser_venv_py39\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\computer15\\desktop\\caser_pytorch\\caser_venv_py39\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\computer15\\desktop\\caser_pytorch\\caser_venv_py39\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\computer15\\desktop\\caser_pytorch\\caser_venv_py39\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\computer15\\desktop\\caser_pytorch\\caser_venv_py39\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\computer15\\desktop\\caser_pytorch\\caser_venv_py39\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (1.65.4)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\\users\\computer15\\desktop\\caser_pytorch\\caser_venv_py39\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (2.10.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\computer15\\desktop\\caser_pytorch\\caser_venv_py39\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (2.10.0)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in c:\\users\\computer15\\desktop\\caser_pytorch\\caser_venv_py39\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (2.10.0)\n",
      "Requirement already satisfied: tf-keras>=2.14.1 in c:\\users\\computer15\\desktop\\caser_pytorch\\caser_venv_py39\\lib\\site-packages (from tensorflow-hub>=0.8.0->tensorflow-text) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\computer15\\desktop\\caser_pytorch\\caser_venv_py39\\lib\\site-packages (from astunparse>=1.6.0->tensorflow<2.11,>=2.10.0->tensorflow-text) (0.44.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\computer15\\desktop\\caser_pytorch\\caser_venv_py39\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (2.33.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\computer15\\desktop\\caser_pytorch\\caser_venv_py39\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\computer15\\desktop\\caser_pytorch\\caser_venv_py39\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (3.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\computer15\\desktop\\caser_pytorch\\caser_venv_py39\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (2.32.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\computer15\\desktop\\caser_pytorch\\caser_venv_py39\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\computer15\\desktop\\caser_pytorch\\caser_venv_py39\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\computer15\\desktop\\caser_pytorch\\caser_venv_py39\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (3.0.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\computer15\\desktop\\caser_pytorch\\caser_venv_py39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (5.4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\computer15\\desktop\\caser_pytorch\\caser_venv_py39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\computer15\\desktop\\caser_pytorch\\caser_venv_py39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\computer15\\desktop\\caser_pytorch\\caser_venv_py39\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\computer15\\desktop\\caser_pytorch\\caser_venv_py39\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (8.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\computer15\\desktop\\caser_pytorch\\caser_venv_py39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\computer15\\desktop\\caser_pytorch\\caser_venv_py39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\computer15\\desktop\\caser_pytorch\\caser_venv_py39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\computer15\\desktop\\caser_pytorch\\caser_venv_py39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (2024.7.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\computer15\\desktop\\caser_pytorch\\caser_venv_py39\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (2.1.5)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\computer15\\desktop\\caser_pytorch\\caser_venv_py39\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (3.20.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\computer15\\desktop\\caser_pytorch\\caser_venv_py39\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\computer15\\desktop\\caser_pytorch\\caser_venv_py39\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files saved as course_codes.npy and course_embeddings.npy.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text  # ต้องเพิ่มเพื่อรองรับ SentencepieceOp\n",
    "\n",
    "# โหลดโมเดล MUSE จาก TensorFlow Hub\n",
    "muse_model = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/3\")\n",
    "\n",
    "# โหลดไฟล์ text.txt\n",
    "course_codes = []\n",
    "course_names = []\n",
    "\n",
    "with open('text.txt', 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        parts = line.strip().split(' ', 1)  # แบ่งเป็น course_id กับ course_name\n",
    "        if len(parts) == 2:\n",
    "            course_id, course_name = parts\n",
    "            course_codes.append(int(course_id))\n",
    "            course_names.append(course_name)\n",
    "\n",
    "# สร้าง embeddings จาก MUSE สำหรับชื่อคอร์ส\n",
    "course_embeddings = muse_model(course_names).numpy()\n",
    "\n",
    "# บันทึกคอร์สโค้ดเป็นไฟล์ .npy\n",
    "np.save('course_codes.npy', np.array(course_codes))\n",
    "\n",
    "# บันทึก embeddings เป็นไฟล์ .npy\n",
    "np.save('course_embeddings.npy', course_embeddings)\n",
    "\n",
    "print(\"Files saved as course_codes.npy and course_embeddings.npy.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lxml\n",
      "  Downloading lxml-5.3.0-cp39-cp39-win_amd64.whl.metadata (3.9 kB)\n",
      "Downloading lxml-5.3.0-cp39-cp39-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "   ------------------------ --------------- 2.4/3.8 MB 12.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.8/3.8 MB 11.9 MB/s eta 0:00:00\n",
      "Installing collected packages: lxml\n",
      "Successfully installed lxml-5.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lxml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Courses data has been saved to courses_data.json.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Function to extract course details\n",
    "def extract_course_details(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    courses = []\n",
    "    \n",
    "    # Extract all course rows by identifying 'tr' tags with 'post-' ID pattern\n",
    "    course_rows = soup.find_all('tr', id=lambda x: x and x.startswith('post-'))\n",
    "    \n",
    "    for row in course_rows:\n",
    "        course = {}\n",
    "        \n",
    "        # Extract the course name\n",
    "        course_name_tag = row.find('strong').find('a')\n",
    "        course['course_name'] = course_name_tag.text.strip() if course_name_tag else \"Unknown\"\n",
    "        \n",
    "        # Extract the course category\n",
    "        category_tag = row.find('td', class_='taxonomy-stm_lms_course_taxonomy')\n",
    "        course['course_category'] = category_tag.text.strip() if category_tag else \"Unknown\"\n",
    "        \n",
    "        # Extract course post ID\n",
    "        course['post_id'] = row.get('id', 'Unknown').replace('post-', '')\n",
    "        \n",
    "        # Extract course status\n",
    "        course['status'] = row.get('class')[2] if len(row.get('class')) > 2 else \"Unknown\"\n",
    "        \n",
    "        # Add the course details to the list\n",
    "        courses.append(course)\n",
    "    \n",
    "    return courses\n",
    "\n",
    "# Function to process multiple HTML files\n",
    "def process_html_files(file_list):\n",
    "    all_courses = []\n",
    "    \n",
    "    for file_path in file_list:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            html_content = file.read()\n",
    "            course_details = extract_course_details(html_content)\n",
    "            all_courses.extend(course_details)\n",
    "    \n",
    "    return all_courses\n",
    "\n",
    "# List of the HTML files you provided\n",
    "html_files = [\n",
    "    'Courses ‹ Robotic Learning Hub — WordPress.html',\n",
    "    'Courses ‹ Robotic Learning Hub — WordPress2.html',\n",
    "    'Courses ‹ Robotic Learning Hub — WordPress.html'\n",
    "]\n",
    "\n",
    "# Process all HTML files and gather course details\n",
    "courses_data = process_html_files(html_files)\n",
    "\n",
    "# Save the extracted data to a JSON file\n",
    "with open('courses_data.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(courses_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"Courses data has been saved to courses_data.json.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories added and saved to anonymized_combined_output_with_categories.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the course data from the JSON file\n",
    "with open('courses_data.json', 'r', encoding='utf-8') as json_file:\n",
    "    course_data = json.load(json_file)\n",
    "\n",
    "# Load your anonymized_combined_output.csv\n",
    "df = pd.read_csv('anonymized_combined_output.csv')\n",
    "\n",
    "# Add a 'Category' column by mapping 'Course Name' to the categories from the JSON file\n",
    "# The JSON file structure is expected to have 'course_name' as keys and 'course_category' as values\n",
    "course_mapping = {course['course_name']: course['course_category'] for course in course_data}\n",
    "df['Category'] = df['Course Name'].map(course_mapping)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV\n",
    "df.to_csv('anonymized_combined_output_with_categories.csv', index=False)\n",
    "\n",
    "print(\"Categories added and saved to anonymized_combined_output_with_categories.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caser_venv_py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
