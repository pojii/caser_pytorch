{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Name                       Email             External Id  \\\n",
      "0         ANONYMIZED_NAME            anonymized_email  ANONYMIZED_EXTERNAL_ID   \n",
      "1         ANONYMIZED_NAME            anonymized_email  ANONYMIZED_EXTERNAL_ID   \n",
      "2         ANONYMIZED_NAME            anonymized_email  ANONYMIZED_EXTERNAL_ID   \n",
      "3  PAUL-LOUIS CREMADEILLS  paullouis.crem@kmutt.ac.th             66540460021   \n",
      "4  PAUL-LOUIS CREMADEILLS  paullouis.crem@kmutt.ac.th             66540460021   \n",
      "\n",
      "                                           Course             Course ID_x  \\\n",
      "0  Exploratory Data Analysis for Machine Learning  Q9Avpol0EeqAWhIJ6hhvFw   \n",
      "1  Exploratory Data Analysis for Machine Learning  Q9Avpol0EeqAWhIJ6hhvFw   \n",
      "2  Exploratory Data Analysis for Machine Learning  Q9Avpol0EeqAWhIJ6hhvFw   \n",
      "3               Neural Networks and Deep Learning  W_mOXCrdEeeNPQ68_4aPpA   \n",
      "4               Neural Networks and Deep Learning  W_mOXCrdEeeNPQ68_4aPpA   \n",
      "\n",
      "                                         Course Slug       University  \\\n",
      "0  ibm-exploratory-data-analysis-for-machine-lear...              IBM   \n",
      "1  ibm-exploratory-data-analysis-for-machine-lear...              IBM   \n",
      "2  ibm-exploratory-data-analysis-for-machine-lear...              IBM   \n",
      "3                      neural-networks-deep-learning  DeepLearning.AI   \n",
      "4                      neural-networks-deep-learning  DeepLearning.AI   \n",
      "\n",
      "            Enrollment Time          Class Start Time  \\\n",
      "0  2023-08-16T07:23:09.000Z  2023-08-14T07:00:00.000Z   \n",
      "1  2023-08-16T07:23:09.000Z  2023-08-14T07:00:00.000Z   \n",
      "2  2023-08-16T07:23:09.000Z  2023-08-14T07:00:00.000Z   \n",
      "3  2023-12-06T04:32:52.000Z  2023-12-11T08:00:00.000Z   \n",
      "4  2023-12-06T04:32:52.000Z  2023-12-11T08:00:00.000Z   \n",
      "\n",
      "             Class End Time  ... Unnamed: 21     category  Unnamed: 22  \\\n",
      "0  2023-09-25T06:59:59.000Z  ...         NaN  Engineering          NaN   \n",
      "1  2023-09-25T06:59:59.000Z  ...         NaN  Engineering          NaN   \n",
      "2  2023-09-25T06:59:59.000Z  ...         NaN  Engineering          NaN   \n",
      "3  2024-01-15T07:59:59.000Z  ...         NaN  Engineering          NaN   \n",
      "4  2024-01-15T07:59:59.000Z  ...         NaN  Engineering          NaN   \n",
      "\n",
      "  Unnamed: 23 Unnamed: 24 Unnamed: 25 Unnamed: 26 Unnamed: 27   l  mas  \n",
      "0         NaN         NaN         NaN         NaN         NaN NaN  NaN  \n",
      "1         NaN         NaN         NaN         NaN         NaN NaN  NaN  \n",
      "2         NaN         NaN         NaN         NaN         NaN NaN  NaN  \n",
      "3         NaN         NaN         NaN         NaN         NaN NaN  NaN  \n",
      "4         NaN         NaN         NaN         NaN         NaN NaN  NaN  \n",
      "\n",
      "[5 rows x 62 columns]\n",
      "Merged file saved as 'merged_usage_course.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "usage_report_df = pd.read_csv('usage-report.csv')\n",
    "course_df = pd.read_csv('course.csv')\n",
    "\n",
    "# Merge the two dataframes on the 'Course' column\n",
    "merged_df = pd.merge(usage_report_df, course_df, on='Course', how='left')\n",
    "\n",
    "# Check the merged dataframe\n",
    "print(merged_df.head())\n",
    "\n",
    "# Save the merged result as a new CSV file\n",
    "merged_df.to_csv('merged_usage_course.csv', index=False)\n",
    "\n",
    "print(\"Merged file saved as 'merged_usage_course.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique 'Domain' values:\n",
      "data-science\n",
      "nan\n",
      "business\n",
      "personal-development\n",
      "information-technology\n",
      "computer-science\n",
      "language-learning\n",
      "social-sciences\n",
      "physical-science-and-engineering\n",
      "arts-and-humanities\n",
      "life-sciences\n",
      "math-and-logic\n",
      "Unique 'Domain' values saved in 'unique_domains.txt'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the merged dataset\n",
    "merged_df = pd.read_csv('merged_usage_course.csv')\n",
    "\n",
    "# Get unique values from the 'Domain' column\n",
    "unique_domains = merged_df['Domain'].unique()\n",
    "\n",
    "# Convert the unique values to a list for easier handling\n",
    "unique_domains_list = unique_domains.tolist()\n",
    "\n",
    "# Print the unique domains\n",
    "print(\"Unique 'Domain' values:\")\n",
    "for domain in unique_domains_list:\n",
    "    print(domain)\n",
    "\n",
    "# Optionally, save the unique domains to a text file\n",
    "with open('unique_domains.txt', 'w') as f:\n",
    "    for domain in unique_domains_list:\n",
    "        f.write(f\"{domain}\\n\")\n",
    "\n",
    "print(\"Unique 'Domain' values saved in 'unique_domains.txt'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered dataset saved as 'filtered_usage_course.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the merged dataset\n",
    "merged_df = pd.read_csv('merged_usage_course.csv')\n",
    "\n",
    "# Define the list of domains to filter out\n",
    "domains_to_remove = ['nan', 'business', 'personal-development', 'language-learning', 'social-sciences', 'arts-and-humanities', 'life-sciences']\n",
    "\n",
    "# Filter the dataset to remove rows where 'Domain' is in the list\n",
    "filtered_df = merged_df[~merged_df['Domain'].isin(domains_to_remove)]\n",
    "\n",
    "# Save the filtered dataset to a new CSV file\n",
    "filtered_df.to_csv('filtered_usage_course.csv', index=False)\n",
    "\n",
    "# Display filtered DataFrame\n",
    "print(\"Filtered dataset saved as 'filtered_usage_course.csv'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caser_venv_py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
